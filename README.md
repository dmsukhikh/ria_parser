# RiaParser - система агрегации данных для получения статей с [ria.ru](https://ria.ru/)
Проект представляет собой ETL-систему с API-сервером, для получения полученной информации из базы данных. В частности, проект использует следующие технологии:
- Scrapy - как фреймворк для парсинга веб-страниц
- PostgreSQL - как базу данных
- Flask - как фреймворк для создания API-сервера
## Требования
Для работы проекта необходимы:
- Docker и docker-compose
- Любой способ подключаться к базам данных
## Установка
Установите docker-compose, соберите в корневой директории проекта образы, затем запустите контейнеры:
```
docker-compose build
docker-compose up
```
## Использование
Краулер будет запускаться в начале каждого часа и заполнять базу данных. При желании, можно поправить файл crawler/crontabFile, чтобы изменить частоту запуска краулера, потом пересобрать образы. Получить доступ к базе данных можно через localhost:8085. Например, так будет выглядеть подключение через psql:
```
psql -d ria -U crawler -h localhost -p 8085
# Password: entity228
```
При желании можно поменять пароль пользователя: в docker-compose.yml и в crawler/crawler/settings.py. Также, можно развернуть эту базу данных на любом сервере и получать по сети данные любым удобным вам способом - на что хватит вашей фантазии.
Подробное описание каждого элемента системы будет добавлено позже
