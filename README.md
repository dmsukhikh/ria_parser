# RiaParser - система агрегации данных для получения статей с [ria.ru](https://ria.ru/)
Проект представляет собой ETL-систему с API-сервером, для получения полученной информации из базы данных. В частности, проект использует следующие технологии:
- Scrapy - как фреймворк для парсинга веб-страниц
- PostgreSQL - как базу данных
- Flask - как фреймворк для создания API-сервера
## Требования
Для работы проекта необходимы:
- Docker и docker-compose
- Любой способ подключаться к базам данных
## Установка
Установите docker-compose, соберите в корневой директории проекта образы, затем запустите контейнеры:
```
docker-compose build
docker-compose up
```
## Использование
API-сервер доступен по адресу ```http://localhost:9090```. Доступны следующие endpoint'ы:
- ```/article/<id>``` - получить полную информацию по статье с id = *<id>*
- ```/articles``` - получить список статей с заданными критериями. Доступны следующие query-параметры:
  - ```tag=<tag>``` - получить все статьи с тегом *<tag>*
  - ```date=<date>``` - получить все статьи, опубликованные в определенный день. День задается в формате **YYYY-MM-DD**. Если это поле не задано, используется текущий день
  - ```from=<x>&to=<y>``` - получить все статьи, опубликованные со дня *x* по день *y*. Формат дней такой же. Если эти поля не заданы, используется текущий день
  - ```limit=x&page=y``` - получить *y*-тые *x* статей. По умолчанию, y = 1, x = 10
Query-параметры можно комбинировать. Следующий запрос выведет вторые 10 статей с тегом "РТУ МИРЭА", опубликованные за июнь 2025 года:
```
http://localhost:9090/articles?tag=РТУ МИРЭА&from=2025-06-01&to=2025-06-30&page=2
```
По умолчанию, краулер запускается в начале каждого часа. Можно запустить паука немедленно средствами docker:
```
docker exec ria-crawl scrapy crawl ria
```
